{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset parameters.\n",
    "NUM_CHANNELS = 1  # BW images\n",
    "NUM_CLASSES = 10\n",
    "PIXEL_DEPTH = 255  # pixel value [0,255]\n",
    "DATA_TYPE = 'tf.float32'\n",
    "VAL_SET_SIZE = 0  # create validation set from training set\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 0.001\n",
    "training_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network parameters.\n",
    "SEED = 2\n",
    "CONV1_DEEP = 32  # No.filters for 1st Conv layer.\n",
    "CONV1_SIZE = 5  # size of 1st Conv layer.\n",
    "CONV2_DEEP = 64  # No.filters for 2nd Conv layer.\n",
    "CONV2_SIZE = 5  # size of 2nd Conv layer.\n",
    "FC_SIZE = 512  # No. neurons for 1st FC layer.\n",
    "\n",
    "# File parameters\n",
    "DATA_PATH = 'mnist_'\n",
    "TRAIN_IMAGES_PATH = 'train-images-idx3-ubyte.gz'\n",
    "TRAIN_LABELS_PATH = 'train-labels-idx1-ubyte.gz'\n",
    "TEST_IMAGES_PATH = 't10k-images-idx3-ubyte.gz'\n",
    "TEST_LABELS_PATH = 't10k-labels-idx1-ubyte.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare MNIST data.\n",
    "# Functions for extracting data from files\n",
    "def read32(bytestream):\n",
    "    dt = np.dtype(np.uint32)\n",
    "    dt = dt.newbyteorder('>')\n",
    "    return np.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "\n",
    "def extract_images(filename):\n",
    "    \"\"\" extract images into 4D uint8 tensor:\n",
    "        - 32 bits magic number == 2051\n",
    "        - 3x32 bits num_images, rows, cols\n",
    "        - data, reshaped to 4D tensor [image index, y, x, channels]\n",
    "    \"\"\"\n",
    "    print('Extracting image file', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        magic = read32(bytestream)\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Invalid magic number %d in MNIST image file: %s' % (magic, filename))\n",
    "        num_images = read32(bytestream)\n",
    "        rows = read32(bytestream)\n",
    "        cols = read32(bytestream)\n",
    "        buf = bytestream.read(rows * cols * num_images * NUM_CHANNELS)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8)\n",
    "        data = data.reshape(num_images, rows, cols, NUM_CHANNELS)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename):\n",
    "    \"\"\"Extract the labels into uint8 tensor\n",
    "        - 32 bits magic number == 2049\n",
    "        - 32 bits num_labels\n",
    "        - labels, 2D tensor [image index, y, x, channels]\n",
    "    \"\"\"\n",
    "    print('Extracting label file', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        magic = read32(bytestream)\n",
    "        if magic != 2049:\n",
    "            raise ValueError(\n",
    "                'Invalid magic number %d in MNIST label file: %s' %\n",
    "                (magic, filename))\n",
    "        num_items = read32(bytestream)\n",
    "        buf = bytestream.read(num_items)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting image file mnist_train-images-idx3-ubyte.gz\n",
      "Extracting label file mnist_train-labels-idx1-ubyte.gz\n",
      "Extracting image file mnist_t10k-images-idx3-ubyte.gz\n",
      "Extracting label file mnist_t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Extract images/labels from given dataset\n",
    "img_train = extract_images(DATA_PATH + TRAIN_IMAGES_PATH)\n",
    "label_train = extract_labels(DATA_PATH + TRAIN_LABELS_PATH)\n",
    "img_test = extract_images(DATA_PATH + TEST_IMAGES_PATH)\n",
    "label_test = extract_labels(DATA_PATH + TEST_LABELS_PATH)\n",
    "\n",
    "if VAL_SET_SIZE:\n",
    "    img_validation = img_train[:VAL_SET_SIZE, ...]\n",
    "    label_validation = label_train[:VAL_SET_SIZE]\n",
    "    img_train = img_train[VAL_SET_SIZE:, ...]\n",
    "    label_train = label_train[VAL_SET_SIZE:]\n",
    "    img_validation = np.array(img_validation, np.float32)\n",
    "    img_validation = (img_validation - PIXEL_DEPTH / 2) / PIXEL_DEPTH\n",
    "\n",
    "# Convert to float32.\n",
    "img_train, img_test = np.array(img_train, np.float32), np.array(img_test, np.float32)\n",
    "img_train, img_test = (img_train - PIXEL_DEPTH / 2) / PIXEL_DEPTH, (img_test - PIXEL_DEPTH / 2) / PIXEL_DEPTH\n",
    "\n",
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((img_train, label_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "# Create some wrappers for simplicity.\n",
    "def conv_2d(x, weights, bias, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation.\n",
    "    x = tf.nn.conv2d(x, weights, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, bias)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool_2d(x, k=2):\n",
    "    # MaxPool2D wrapper.\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainable weights and biases for 2 conv layers and FC layers\n",
    "# Using TruncatedNormal for initialization\n",
    "weight_initializer = tf.initializers.TruncatedNormal(stddev=0.1, seed=SEED)\n",
    "weights = {\n",
    "    # Conv Layer 1: 5x5 conv, 1 input, 32 filters (MNIST has 1 color channel only).\n",
    "    'conv1_w': tf.Variable(\n",
    "        weight_initializer([CONV1_SIZE, CONV1_SIZE, NUM_CHANNELS, CONV1_DEEP])),\n",
    "    # Conv Layer 2: 5x5 conv, 32 inputs, 64 filters.\n",
    "    'conv2_w': tf.Variable(\n",
    "        weight_initializer([CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV2_DEEP])),\n",
    "    # FC Layer 1: 7*7*64 inputs, 512 units.\n",
    "    'fc_w': tf.Variable(\n",
    "        weight_initializer([img_test.shape[1] // 4 * img_test.shape[2] // 4 * CONV2_DEEP, FC_SIZE])),\n",
    "    # FC Out Layer: 512 inputs, 10 units (total number of classes)\n",
    "    'out_w': tf.Variable(weight_initializer([FC_SIZE, NUM_CLASSES])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'conv1_b': tf.Variable(tf.zeros([CONV1_DEEP])),\n",
    "    'conv2_b': tf.Variable(tf.zeros([CONV2_DEEP])),\n",
    "    'fc_b': tf.Variable(tf.zeros([FC_SIZE])),\n",
    "    'out_b': tf.Variable(tf.zeros([NUM_CLASSES]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model.\n",
    "def conv_net(x):\n",
    "    # Input: a batch of 28x28 grayscale images\n",
    "    x = tf.reshape(x, [-1, 28, 28, NUM_CHANNELS])\n",
    "\n",
    "    # Conv layer. Output shape: 28x28x32 ('SAME' padding)\n",
    "    conv1 = conv_2d(x, weights['conv1_w'], biases['conv1_b'])\n",
    "    # Max Pooling. Output shape: 14x14x32\n",
    "    conv1 = maxpool_2d(conv1, k=2)\n",
    "\n",
    "    # Conv layer. Output shape: 14x14x64 ('SAME' padding)\n",
    "    conv2 = conv_2d(conv1, weights['conv2_w'], biases['conv2_b'])\n",
    "    # Max Pooling. Output shape: 7x7x64\n",
    "    conv2 = maxpool_2d(conv2, k=2)\n",
    "\n",
    "    # Reshape conv2 output to fit FC layer input, Output shape: [-1, 7*7*64].\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['fc_w'].get_shape().as_list()[0]])\n",
    "\n",
    "    # Fc layer, Output shape: [-1, 1024].\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['fc_w']), biases['fc_b'])\n",
    "    # Apply ReLU to fc1 output for non-linearity.\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    # Fully connected layer, Output shape: [-1, 10].\n",
    "    out = tf.add(tf.matmul(fc1, weights['out_w']), biases['out_b'])\n",
    "    # Apply softmax to normalize the logits to a probability distribution.\n",
    "    return tf.nn.softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optimization process.\n",
    "\n",
    "# Cross-Entropy loss function.\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    # Encode label to a one hot vector.\n",
    "    y_true = tf.one_hot(y_true, depth=NUM_CLASSES)\n",
    "    # Clip prediction values to avoid log(0) error.\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    # Compute cross-entropy.\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
    "\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "\n",
    "\n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = conv_net(x)\n",
    "        loss = cross_entropy(pred, y)\n",
    "\n",
    "    # Compute gradients and update W and b following gradients\n",
    "    trainable_variables = list(weights.values()) + list(biases.values())\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1, loss: 141.361572, accuracy: 0.695312\n",
      "step: 2, loss: 59.312401, accuracy: 0.898438\n",
      "step: 3, loss: 42.479141, accuracy: 0.867188\n",
      "step: 4, loss: 42.982277, accuracy: 0.906250\n",
      "step: 5, loss: 25.200092, accuracy: 0.945312\n",
      "step: 6, loss: 21.710499, accuracy: 0.968750\n",
      "step: 7, loss: 37.268360, accuracy: 0.906250\n",
      "step: 8, loss: 16.409821, accuracy: 0.968750\n",
      "step: 9, loss: 34.755798, accuracy: 0.945312\n",
      "step: 10, loss: 16.114361, accuracy: 0.953125\n",
      "step: 11, loss: 10.829327, accuracy: 0.968750\n",
      "step: 12, loss: 8.173870, accuracy: 0.976562\n",
      "step: 13, loss: 15.448557, accuracy: 0.968750\n",
      "step: 14, loss: 19.054787, accuracy: 0.945312\n",
      "step: 15, loss: 16.696077, accuracy: 0.960938\n",
      "step: 16, loss: 13.700947, accuracy: 0.960938\n",
      "step: 17, loss: 11.703341, accuracy: 0.976562\n",
      "step: 18, loss: 12.377934, accuracy: 0.984375\n",
      "step: 19, loss: 13.658243, accuracy: 0.976562\n",
      "step: 20, loss: 7.029793, accuracy: 0.984375\n",
      "step: 21, loss: 18.095743, accuracy: 0.976562\n",
      "step: 22, loss: 14.569902, accuracy: 0.976562\n",
      "step: 23, loss: 11.061077, accuracy: 0.968750\n",
      "step: 24, loss: 10.657516, accuracy: 0.960938\n",
      "step: 25, loss: 5.824610, accuracy: 0.992188\n",
      "step: 26, loss: 9.050177, accuracy: 0.976562\n",
      "step: 27, loss: 18.812431, accuracy: 0.960938\n",
      "step: 28, loss: 12.170196, accuracy: 0.984375\n",
      "step: 29, loss: 22.001602, accuracy: 0.960938\n",
      "step: 30, loss: 7.325305, accuracy: 0.984375\n",
      "step: 31, loss: 5.836302, accuracy: 0.984375\n",
      "step: 32, loss: 4.798365, accuracy: 0.992188\n",
      "step: 33, loss: 5.762313, accuracy: 0.992188\n",
      "step: 34, loss: 13.666767, accuracy: 0.960938\n",
      "step: 35, loss: 14.482471, accuracy: 0.976562\n",
      "step: 36, loss: 6.848991, accuracy: 0.976562\n",
      "step: 37, loss: 7.224382, accuracy: 0.984375\n",
      "step: 38, loss: 5.172302, accuracy: 0.984375\n",
      "step: 39, loss: 6.176563, accuracy: 0.992188\n",
      "step: 40, loss: 4.646427, accuracy: 0.984375\n",
      "step: 41, loss: 11.657354, accuracy: 0.976562\n",
      "step: 42, loss: 3.967816, accuracy: 0.992188\n",
      "step: 43, loss: 11.827815, accuracy: 0.992188\n",
      "step: 44, loss: 5.443879, accuracy: 0.984375\n",
      "step: 45, loss: 3.969116, accuracy: 0.984375\n",
      "step: 46, loss: 2.272192, accuracy: 1.000000\n",
      "step: 47, loss: 8.940295, accuracy: 0.984375\n",
      "step: 48, loss: 2.002187, accuracy: 1.000000\n",
      "step: 49, loss: 6.467338, accuracy: 0.984375\n",
      "step: 50, loss: 9.043748, accuracy: 0.976562\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "\n",
    "    if step % display_step == 0:\n",
    "        pred = conv_net(batch_x)\n",
    "        loss = cross_entropy(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step/display_step, loss, acc))\n",
    "        train_losses.append(loss)\n",
    "\n",
    "        # Test model on validation set.\n",
    "        # pred = conv_net(img_validation)\n",
    "        # val_loss = cross_entropy(pred, label_validation)\n",
    "        # print(\"Validation Accuracy: %f\" % val_loss)\n",
    "        # val_losses.append(val_loss/VAL_SET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.986700\n"
     ]
    }
   ],
   "source": [
    "# Test model.\n",
    "pred = conv_net(img_test)\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, label_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [
    {
     "id": "8979",
     "title": "MNIST手写数字数据集"
    }
   ],
   "description": "",
   "notebookId": "44757",
   "source": "ailab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}